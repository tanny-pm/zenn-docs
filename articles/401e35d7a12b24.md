---
title: "Beautiful Soupã§åº—èˆ—æƒ…å ±ã‚’å–å¾—ã—ã¦Googleãƒãƒƒãƒ—ã«è¡¨ç¤ºã™ã‚‹"
emoji: "ğŸ "
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: [python, beautifulsoup]
published: false
---

# åº—èˆ—æƒ…å ±ã‚’å–å¾—ã™ã‚‹

## ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

```py
import csv

import requests
from bs4 import BeautifulSoup
```

## ãƒ‡ãƒ¼ã‚¿ã®å–å¾—

```py
PAGE_URL = "https://www.adana.co.jp/jp/contents/retailer/shop.html"
r = requests.get(PAGE_URL)
r.encoding = r.apparent_encoding # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’UTF-8ã«è¨­å®š

soup = BeautifulSoup(r.text)
soup.title
```

```html
<title>è²©å£²ç‰¹ç´„åº—ã‚’ã•ãŒã™ | ADA - SHOP</title>
```

```py
# ï¼‘ç•ªç›®ã®åº—èˆ—æƒ…å ±ã‚’å–å¾—
soup.find("a", class_=["basic-tr", "basic-tr-link"])
```

```html
<a
  class="basic-tr-link"
  href="https://www.sample.com/"
  rel="noopener"
  target="_blank"
>
  <div class="basic-td">
    <p>
      <span class="shopname"
        >åº—èˆ—å<i class="fas fa-external-link-alt"></i></span
      ><br />
      ä½æ‰€<br />
      <i class="fas fa-phone"></i>111-2222-3333<br />
      å–¶æ¥­æ™‚é–“ï¼š10:00-19:00<br />å®šä¼‘æ—¥ï¼šå¹´ä¸­ç„¡ä¼‘
    </p>
  </div>
  <!-- çœç•¥ -->
</a>
```

## ãƒ‡ãƒ¼ã‚¿ã®æ•´å½¢

```py
shop_list = []

for row in soup.find_all("a", class_=["basic-tr", "basic-tr-link"]):
    shop_info = {}
    shop_detail = row.div.p.get_text(',', strip=True).split(',')

    shop_info["name"] = shop_detail[0]
    shop_info["url"] = row.get("href")
    shop_info["address"] = shop_detail[1]
    shop_info["phone"] = shop_detail[2]
    shop_info["open"] = " ".join(shop_detail[3:])

    shop_list.append(shop_info)

shop_list[0]
```

```py
{'name': 'åº—èˆ—å',
 'url': 'https://www.sample.com/',
 'address': 'ä½æ‰€',
 'phone': '111-2222-3333',
 'open': 'å–¶æ¥­æ™‚é–“ï¼š10:00-19:00 å®šä¼‘æ—¥ï¼šå¹´ä¸­ç„¡ä¼‘'}
```

## CSVå‡ºåŠ›

```py
with open("shop_list.csv", "w") as f:
    writer = csv.DictWriter(f, fieldnames = shop_list[0].keys())
    writer.writeheader()
    writer.writerows(shop_list)
```

# Googleãƒãƒƒãƒ—ã«è¡¨ç¤ºã™ã‚‹

# ãŠã‚ã‚Šã«
